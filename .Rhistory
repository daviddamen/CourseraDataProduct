df <- read.csv("pml-training.csv", na.strings=c("NA", "", "#DIV/0!"))
df <- df[,-(1:7)]
df_na_count <- apply(df, 2, function(x){ sum(is.na(x)) })
df <- df[, which(df_na_count == 0)]
?randomForest
set.seed(666)
inTrain <- createDataPartition(df$classe, p=0.75, list=FALSE)
training <- df[inTrain,]
testing <- df[-inTrain,]
regressors <- training[, 1:(length(names(training)) - 1)]
set.seed(666)
model.rf <- randomForest(y=training$classe, x=regressors)
plot(model.rf$finalModel)
testing.rf.predict <- predict(model.rf, newdata=testing)
confusionMatrix(testing$classe, testing.rf.predict)
set.seed(666)
model.gbm <- train(y=training$classe, x=regressors, method="gbm", verbose=FALSE)
plot(model.gbm$finalModel)
testing.gbm.predict <- predict(model.gbm, newdata=testing)
confusionMatrix(testing$classe, testing.gbm.predict)
library(caret)
library(randomForest)
df <- read.csv("pml-training.csv", na.strings=c("NA", "", "#DIV/0!"))
df <- df[,-(1:7)]
df_na_count <- apply(df, 2, function(x){ sum(is.na(x)) })
df <- df[, which(df_na_count == 0)]
set.seed(666)
inTrain <- createDataPartition(df$classe, p=0.75, list=FALSE)
training <- df[inTrain,]
testing <- df[-inTrain,]
model <- randomForest(y=training$classe, x=training[, 1:(length(names(training)) - 1)])
testing.predict <- predict(model, newdata=testing)
confusionMatrix(testing$classe, testing.predict)
plot(model$finalModel)
plot(model)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
df2 <- read.csv("pml-testing.csv", na.strings=c("NA", "", "#DIV/0!"))
summary(df2)
t2.predict <- predict(model, newdata=df2)
df2_na_count <- apply(df2, 2, function(x){ sum(is.na(x)) })
df2 <- df2[, which(df2_na_count == 0)]
t2.predict <- predict(model, newdata=df2)
t2.predict
results <- as.character(t2.predict)
resampleHist()
results
pml_write_files(results)
plot(model, log="y")
varImpPlot(model)
df <- df[,-(1:7)]
df_na_count <- apply(df, 2, function(x){ sum(is.na(x)) })
df <- df[, which(df_na_count == 0)]
library(caret)
library(randomForest)
df <- read.csv("pml-training.csv", na.strings=c("NA", "", "#DIV/0!"))
df
str(df)
library(caret)
library(randomForest)
df <- read.csv("pml-training.csv", na.strings=c("NA", "", "#DIV/0!"))
df <- df[,-(1:7)]
df_na_count <- apply(df, 2, function(x){ sum(is.na(x)) })
df <- df[, which(df_na_count == 0)]
set.seed(666)
inTrain <- createDataPartition(df$classe, p=0.75, list=FALSE)
training <- df[inTrain,]
testing <- df[-inTrain,]
model <- randomForest(y=training$classe, x=training[, 1:(length(names(training)) - 1)])
plot(model, log="y")
varImpPlot(model)
model$finalModel
summary(model$finalModel)
summary(model)
importance(model)
p <- qplot(roll_belt, yaw_belt, col=classe, data=training)
p
p + geom_point(aes(x=roll_belt,y=yaw_belt,col=classe),size=5,shape=4,data=training)
qplot(roll_belt,yaw_belt,colour=predRight,data=testing,main="newdata Predictions")
testing$predRight <- testing.predict==testing$classe
testing.predict <- predict(model, newdata=testing)
confusionMatrix(testing$classe, testing.predict)
testing$predRight <- testing.predict==testing$classe
qplot(roll_belt, yaw_belt, colour=predRight,data=testing,main="newdata Predictions")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
install.packages("ElemStatLearn")
install.packages("pgmm")
install.packages("lubridate")
install.packages("forecast")
install.packages("e1071")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
summary(vowel.train)
set.seed(33833)
install.packages("gbm")
library(caret)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
model.1 <- train(y ~ ., data=vowel.train, method="rpart")
model.2 <- train(y ~ ., data=vowel.train, method="gbm")
confusionMatrix(model.1)
confusionMatrix(model.2)
pred.1 <- predict(model.1, data=vowel.test)
pred.2 <- predict(model.2, data=vowel.test)
confusionMatrix(pred.1)
confusionMatrix(pred.2)
set.seed(33833)
model.1 <- train(y ~ ., data=vowel.train, method="rpart")
model.2 <- train(y ~ ., data=vowel.train, method="gbm")
pred.1 <- predict(model.1, newdata=vowel.test)
pred.2 <- predict(model.2, newdata=vowel.test)
confusionMatrix(pred.1)
confusionMatrix(pred.2)
confusionMatrix(vowel.test$y, pred.1)
confusionMatrix(vowel.test$y, pred.2)
library(caret)
library(rpart)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
model.1 <- train(y ~ ., data=vowel.train, method="rpart")
model.2 <- train(y ~ ., data=vowel.train, method="gbm")
pred.1 <- predict(model.1, newdata=vowel.test)
pred.2 <- predict(model.2, newdata=vowel.test)
confusionMatrix(vowel.test$y, pred.1)
confusionMatrix(vowel.test$y, pred.2)
set.seed(33833)
model.1 <- train(y ~ ., data=vowel.train, method="rf")
model.2 <- train(y ~ ., data=vowel.train, method="gbm")
pred.1 <- predict(model.1, newdata=vowel.test)
pred.2 <- predict(model.2, newdata=vowel.test)
confusionMatrix(vowel.test$y, pred.1)
confusionMatrix(vowel.test$y, pred.2)
DF_combined <- data.frame(predict1, predict2, y = vowel.test$y)
fit_combined <- train(y ~ ., data = DF_combined, method = "gam")
predict3 <- predict(fit_combined, newdata = vowel.test)
DF_combined <- data.frame(pred.1, pred.2, y = vowel.test$y)
fit_combined <- train(y ~ ., data = DF_combined, method = "gam")
pred.3 <- predict(fit_combined, newdata = vowel.test)
confusionMatrix(vowel.test$y, pred.3)
library(caret)
library(rpart)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
model.rf <- train(y ~ ., data=vowel.train, method="rf")
model.gbm <- train(y ~ ., data=vowel.train, method="gbm")
pred.rf <- predict(model.rf, newdata=vowel.test)
pred.gbm <- predict(model.gbm, newdata=vowel.test)
combinedTestData <- data.frame(rf.pred=rf.pred.test, gbm.pred=gbm.pred.test, y=vowel.test$y)
comb.fit <- train(y ~., method="gam", data=combinedTestData)
rf.pred.val <- predict(model.rf,vowel.test)
gbm.pred.val <- predict(model.gbm,vowel.test)
combinedValData <- data.frame(rf.pred=rf.pred.val, gbm.pred=gbm.pred.val)
comb.pred.val <- predict(comb.fit,combinedValData)
confusionMatrix(vowel.test$y, pred.1)
confusionMatrix(vowel.test$y, pred.2)
confusionMatrix(vowel.test$y, comb.pred.val)
library(caret)
library(rpart)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
model.rf <- train(y ~ ., data=vowel.train, method="rf")
model.gbm <- train(y ~ ., data=vowel.train, method="gbm")
pred.rf <- predict(model.rf, newdata=vowel.test)
pred.gbm <- predict(model.gbm, newdata=vowel.test)
combinedTestData <- data.frame(rf.pred=pred.rf, gbm.pred=pred.gbm, y=vowel.test$y)
comb.fit <- train(y ~., method="gam", data=combinedTestData)
rf.pred.val <- predict(model.rf,vowel.test)
gbm.pred.val <- predict(model.gbm,vowel.test)
combinedValData <- data.frame(rf.pred=rf.pred.val, gbm.pred=gbm.pred.val)
comb.pred.val <- predict(comb.fit,combinedValData)
confusionMatrix(vowel.test$y, pred.1)
confusionMatrix(vowel.test$y, pred.2)
confusionMatrix(vowel.test$y, comb.pred.val)
?confusionMatrix
confusionMatrix(reference=vowel.test$y, data=pred.1)
confusionMatrix(reference=vowel.test$y, data=pred.2)
confusionMatrix(reference=vowel.test$y, data=pred.1==pred.2)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(training)
set.seed(62433)
model.rf <- train(diagnosis ~ ., data=vowel.train, method="rf")
model.gbm <- train(diagnosis ~ ., data=vowel.train, method="gbm")
model.lda <- train(diagnosis ~ ., data=vowel.train, method="lda")
pred.rf <- predict(model.rf, newdata=testing$diagnosis)
pred.gbm <- predict(model.gbm, newdata=testing$diagnosis)
pred.lda <- predict(model.lda, newdata=testing$diagnosis)
comb <- data.frame(pred.rf, pred.gbm, pred.lda, diagnosis = training$diagnosis)
model.comb <- train(diagnosis ~ ., data = comb, method = "rf")
predict.comb <- predict(model.comb, newdata=testing)
confusionMatrix(data=predict.comb, reference=testing$diagnosis)
set.seed(62433)
model.rf <- train(diagnosis ~ ., data=training, method="rf")
model.gbm <- train(diagnosis ~ ., data=training, method="gbm")
model.lda <- train(diagnosis ~ ., data=training, method="lda")
pred.rf <- predict(model.rf, newdata=testing$diagnosis)
pred.gbm <- predict(model.gbm, newdata=testing$diagnosis)
pred.lda <- predict(model.lda, newdata=testing$diagnosis)
comb <- data.frame(pred.rf, pred.gbm, pred.lda, diagnosis = training$diagnosis)
model.comb <- train(diagnosis ~ ., data = comb, method = "rf")
predict.comb <- predict(model.comb, newdata=testing)
confusionMatrix(data=predict.comb, reference=testing$diagnosis)
pred.rf <- predict(model.rf, newdata=testing)
pred.gbm <- predict(model.gbm, newdata=testing)
pred.lda <- predict(model.lda, newdata=testing)
comb <- data.frame(pred.rf, pred.gbm, pred.lda, diagnosis = training$diagnosis)
model.comb <- train(diagnosis ~ ., data = comb, method = "rf")
predict.comb <- predict(model.comb, newdata=testing)
confusionMatrix(data=predict.comb, reference=testing$diagnosis)
comb <- data.frame(pred.rf, pred.gbm, pred.lda, diagnosis = testing$diagnosis)
model.comb <- train(diagnosis ~ ., data = comb, method = "rf")
predict.comb <- predict(model.comb, newdata=testing)
confusionMatrix(data=predict.comb, reference=testing$diagnosis)
confusionMatrix(data=predict.rf, reference=testing$diagnosis)$accuracy
pred.comb <- predict(model.comb, newdata=testing)
confusionMatrix(data=pred.rf, reference=testing$diagnosis)$accuracy
confusionMatrix(data=pred.rf, reference=testing$diagnosis)
confusionMatrix(data=pred.gbm, reference=testing$diagnosis)
confusionMatrix(data=pred.lda, reference=testing$diagnosis)
confusionMatrix(data=pred.comb, reference=testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
model.lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
install.packages("elasticnet")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
model.lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
plot.enet(model$finalModel, xvar="penalty", use.color=TRUE)
plot.enet(model.lasso$finalModel, xvar="penalty", use.color=TRUE)
?bats
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
?bats
m <- bats(training)
str(training)
m <- bats(training$visitsTumblr)
library(forecast)
m <- bats(tstrain)
fcast <- forecast(m)
plot(fcast)
lines(testing$visitsTumblr)
fcast
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
m <- bats(tstrain)
fcast <- forecast(m, level=95)
plot(fcast)
lines(testing$visitsTumblr)
result <- c()
l <- length(fcast$lower)
for (i in 1:l){
x <- testing$visitsTumblr[i]
a <- fcast$lower[i] < x & x < fcast$upper[i]
result <- c(result, a)
}
sum(result)/l * 100
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
m <- bats(tstrain)
h <- dim(testing)[1]
fcast <- forecast(m, level=95, h=h)
plot(fcast)
lines(testing$visitsTumblr)
accuracy(fcast, testing$visitsTumblr)
result <- c()
l <- length(fcast$lower)
for (i in 1:l){
x <- testing$visitsTumblr[i]
a <- fcast$lower[i] < x & x < fcast$upper[i]
result <- c(result, a)
}
sum(result)/l * 100
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
library(caret)
m <- train(CompressiveStrength ~ ., data=training, method="svmRadial")
install.packages("kernlab")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
library(caret)
m <- train(CompressiveStrength ~ ., data=training, method="svmRadial")
p <- predict(m, testing)
confusionMatrix(p$CompressiveStrength, testing$CompressiveStrength)
confusionMatrix(testing$CompressiveStrength, p$CompressiveStrength)
confusionMatrix(testing$CompressiveStrength, p)
confusionMatrix(testing$CompressiveStrength, p)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
library(caret)
m <- train(CompressiveStrength ~ ., data=training, method="svmRadial")
p <- predict(m, testing)
confusionMatrix(testing$CompressiveStrength, p)
p
RMSE(p, testing)
?RMSE
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
library(caret)
fit <- train(CompressiveStrength ~ ., data = training, method = "svmRadial")
prediction <- predict(fit, testing)
accuracy(prediction, testing$CompressiveStrength)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
library(caret)
m <- train(CompressiveStrength ~ ., data=training, method="svmRadial")
p <- predict(m, testing)
accuracy(p, testing$CompressiveStrength)
install.packages("devtools")
install.packages(c("GGally", "Hmisc", "caret", "digest", "htmltools", "knitr", "rmarkdown"))
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
install.packages("manipulate")
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot, s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), slider = x(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
install.packages("rCharts")
methods("mean")
methods("show")
methods("lm")
methods("predict")
methods("dgamaa")
methods("dgamma")
methods("colSums")
install.packages("shiny");
install.packages(c("GGally", "R6", "Rcpp", "RcppArmadillo", "RcppEigen", "curl", "devtools", "httr", "kernlab", "knitr", "memoise", "mgcv", "nlme", "pbkrtest", "rstudioapi"))
runApp()
library(shiny)
runApp()
runApp("~/Dropbox/Coursera/DataScience/09-DataProducts/project")
exit
runApp("~/Dropbox/Coursera/DataScience/09-DataProducts/project")
shiny::runApp('~/Dropbox/Coursera/DataScience/09-DataProducts/project')
shiny::runApp('~/Dropbox/Coursera/DataScience/09-DataProducts/project')
runApp("~/Dropbox/Coursera/DataScience/09-DataProducts/project")
?datasets
library(help = "datasets")
?cars
?discoveries
df <- discoveries
summary(df)
str(discoveries)
?eurodist
?faithful
?USArrests
?WorldPhones
?morley
?women
sr(women)
str(women)
df <- women
lenght(women)
length(women)
length(women[1])
length(women[,1])
women[0]
women[0,]
women[1,]
women[14,]
women[15,]
women[16,]
df[lenght(women)+1,] <- list(189, 92.5)
df[length(women)+1,] <- list(189, 92.5)
df
df <- women
df[length(women[,1])+1,] <- list(189, 92.5)
df
plot(df)
womenDF <- women
womenDF[,2] <- womenDF[,2] / 0.453592
plot(womenDF)
womenDF <- women
womenDF[,2] <- womenDF[,2] * 0.453592
plot(womenDF)
?women
womenDF
womenDF[,womenDF$weight] <- womenDF[,womenDF$weight] * 0.453592
women <- womenDF[,womenDF$weight] * 0.453592
womenDF <- women
womenDF$height <- womenDF$height * 2.54
womenDF$weight <- womenDF$weight * 0.453592
womenDF
plot(womenDF$weight, womenDF$height)
plot(womenDF$weight, womenDF$height, col=ifelse(x==, "red", "black"))
shiny::runApp('~/Dropbox/Coursera/DataScience/09-DataProducts/project')
shiny::runApp('~/Dropbox/Coursera/DataScience/09-DataProducts/project')
runApp("~/Dropbox/Coursera/DataScience/09-DataProducts/project", display.mode='showcase')
runApp("~/Dropbox/Coursera/DataScience/09-DataProducts/project", display.mode='showcase')
runApp("~/Dropbox/Coursera/DataScience/09-DataProducts/project", display.mode='showcase')
shiny::runApp('~/Dropbox/Coursera/DataScience/09-DataProducts/project')
runApp("~/Dropbox/Coursera/DataScience/09-DataProducts/project", display.mode='showcase')
runApp("~/Dropbox/Coursera/DataScience/09-DataProducts/project", display.mode='showcase')
runApp("~/Dropbox/Coursera/DataScience/09-DataProducts/project", display.mode='showcase')
?submitButton
runApp("~/Dropbox/Coursera/DataScience/09-DataProducts/project", display.mode='showcase')
?numericInput
shiny::runApp('~/Dropbox/Coursera/DataScience/09-DataProducts/project')
shiny::runApp('~/Dropbox/Coursera/DataScience/09-DataProducts/project')
?plot
shiny::runApp('~/Dropbox/Coursera/DataScience/09-DataProducts/project')
shiny::runApp('~/Dropbox/Coursera/DataScience/09-DataProducts/project')
shiny::runApp('~/Dropbox/Coursera/DataScience/09-DataProducts/project')
shiny::runApp('~/Dropbox/Coursera/DataScience/09-DataProducts/project')
shiny::runApp('~/Dropbox/Coursera/DataScience/09-DataProducts/project')
shiny::runApp('~/Dropbox/Coursera/DataScience/09-DataProducts/project')
shiny::runApp('~/Dropbox/Coursera/DataScience/09-DataProducts/project')
Compare yourself to the average woman of 1975
?women
?plot
womenDF <- women
womenDF$height <- womenDF$height * 2.54
womenDF$weight <- womenDF$weight * 0.453592
summary(womenDF)
height <- 189
weight <- 92.1
womenDF <- womenDF[length(womenDF[,1])+1,] <- list(height, weight)
womenDF
shiny::runApp('~/Dropbox/Coursera/DataScience/09-DataProducts/project')
shiny::runApp('~/Dropbox/Coursera/DataScience/09-DataProducts/project')
install.packages("shiny")
shiny::runApp('~/Dropbox/Coursera/DataScience/09-DataProducts/project')
